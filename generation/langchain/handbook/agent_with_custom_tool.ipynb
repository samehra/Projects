{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "N3x8LxDubC3B"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samehra/Projects/blob/master/generation/langchain/handbook/agent_with_custom_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Agent and Custom Tool with LangChain\n",
        "This notebook contains code for creating a custom:\n",
        "1. Tool that \"reads\" annual reports\n",
        "2. Agent that uses tools to answer queries\n",
        "\n",
        "In our example, the PDF is an annual report for Meta Platforms (formerly known as Facebook).\n",
        "\n"
      ],
      "metadata": {
        "id": "gmYJu6M1eRMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0.  Install dependencies"
      ],
      "metadata": {
        "id": "N3x8LxDubC3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "zMINRKTEZ7Gd",
        "outputId": "87a5201f-7eb1-4382-91fb-099f63a08533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.144)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "hA-MpsaOP8DC",
        "outputId": "778f13dc-b698-4da0-c8d9-bfd8395afb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "1AytsWBIQ6Zh",
        "outputId": "a94ac34c-7bf0-4b3a-8b73-fddf4ce51366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.9/dist-packages (0.3.21)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from chromadb) (3.0.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.10.7)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.2.2)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.5.20)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.28.2)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.95.1)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.9/dist-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.98)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.2)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (8.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "D82QKqEpUD-B",
        "outputId": "35be5b35-3074-4e92-ac27-6a90b3abd9b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (0.3.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.28.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "QdAGqGU0N0N0",
        "outputId": "e4913f23-50e1-413c-f204-a09d20d62c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.9/dist-packages (3.8.0)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from pypdf) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. PDF Document Ingestion"
      ],
      "metadata": {
        "id": "WP4kma9pWDts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load $META's annual report. This may take 1-2 minutes since the PDF is 171 pages\n",
        "meta_annual_report_pdf = \"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/e574646c-c642-42d9-9229-3892b13aabfb.pdf\"\n",
        "# Create your PDF loader\n",
        "loader = PyPDFLoader(meta_annual_report_pdf)\n",
        "# Load the PDF document\n",
        "documents = loader.load()  "
      ],
      "metadata": {
        "id": "vfh_g5uaVx55"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "# Chunk the annual_report\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "MaIuMZx7V0pj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Save the annual report\n",
        "Using ChromaDB, save the annual report to a vector database. \n",
        "\n",
        "This will allow your custom Agent and Tool to later retrieve (use) the annual report for question-answering."
      ],
      "metadata": {
        "id": "6Mfq-hk5Vni7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "vectorstore = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "SLfnioDuPiUY",
        "outputId": "b32a3104-5b2a-45b7-d53f-35183aa7c0ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Create your custom Chain\n",
        "This Chain will be used by your custom Tool (defined next) to answer questions\n",
        "about the annual report that you previously loaded."
      ],
      "metadata": {
        "id": "tBPm7mj2VUKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.base import Chain\n",
        "from typing import Dict, List\n",
        "\n",
        "class AnnualReportChain(Chain):\n",
        "    chain: Chain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        return list(self.chain.input_keys)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        return ['output']\n",
        "\n",
        "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
        "        # Queries the database to get the relevant documents for a given query\n",
        "        query = inputs.get(\"input_documents\", \"\")\n",
        "        docs = vectorstore.similarity_search(query, include_metadata=True)\n",
        "        output = chain.run(input_documents=docs, question=query)\n",
        "        return {'output': output}"
      ],
      "metadata": {
        "id": "7RkzoUBXVVJm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. Create your custom Tool\n",
        "This tool will use the Chain that you just created, under the hood."
      ],
      "metadata": {
        "id": "gss7eALIWmPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize your custom Chain\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\")\n",
        "chain = load_qa_chain(llm)\n",
        "annual_report_chain = AnnualReportChain(chain=chain)\n",
        "\n",
        "# Initialize your custom Tool\n",
        "annual_report_tool = Tool(\n",
        "    name=\"Annual Report\",\n",
        "    func=annual_report_chain.run,\n",
        "    description=\"\"\"\n",
        "    useful for when you need to answer questions about a company's income statement,\n",
        "    cash flow statement, or balance sheet. This tool can help you extract data points like\n",
        "    net income, revenue, free cash flow, and total debt, among other financial line items.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "yh4iYLeJWEpr",
        "outputId": "4484cd14-737d-4c10-88bd-f426d6271b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/langchain/llms/openai.py:676: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Create your custom Agent\n",
        "This Agent uses your custom tool(s) to get things done.\n",
        "\n",
        "For our example, the Agent is given 1 tool (`annual_report_tool` from above) and answers questions about annual reports!\n",
        "\n",
        "The code here is heavily borrowed from [this wonderful GitHub repository](https://github.com/mpaepper/llm_agents), which is created by [Marc PÃ¤pper](https://twitter.com/mpaepper).\n",
        "\n",
        "Marc wrote an [excellent blog post](https://www.paepper.com/blog/posts/intelligent-agents-guided-by-llms/) that explains how Agents work.\n"
      ],
      "metadata": {
        "id": "F0PC0OPbVP7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from typing import Tuple\n",
        "\n",
        "class Agent(BaseModel):\n",
        "    # The large language model that the Agent will use to decide the action to take\n",
        "    llm: BaseModel\n",
        "    # The prompt that the language model will use and append previous responses to\n",
        "    prompt: str\n",
        "    # The list of tools that the Agent can use\n",
        "    tools: List[Tool]\n",
        "    # Adjust this so that the Agent does not loop infinitely\n",
        "    max_loops: int = 5\n",
        "    # The stop pattern is used, so the LLM does not hallucinate until the end\n",
        "    stop_pattern: List[str]\n",
        "\n",
        "    @property\n",
        "    def tool_by_names(self) -> Dict[str, Tool]:\n",
        "        return {tool.name: tool for tool in self.tools}\n",
        "\n",
        "    def run(self, question: str):\n",
        "        name_to_tool_map = {tool.name: tool for tool in self.tools}\n",
        "        previous_responses = []\n",
        "        num_loops = 0\n",
        "        while num_loops < self.max_loops:\n",
        "            num_loops += 1\n",
        "            curr_prompt = prompt.format(previous_responses=('\\n'.join(previous_responses)))\n",
        "            output, tool, tool_input = self._get_next_action(curr_prompt)\n",
        "            if tool == 'Final Answer':\n",
        "                return tool_input\n",
        "            tool_result = name_to_tool_map[tool].run(tool_input)\n",
        "            output += f\"\\n{OBSERVATION_TOKEN} {tool_result}\\n{THOUGHT_TOKEN}\"\n",
        "            print(output)\n",
        "            previous_responses.append(output)\n",
        "\n",
        "    def _get_next_action(self, prompt: str) -> Tuple[str, str, str]:\n",
        "        # Use the LLM to generate the Agent's next action\n",
        "        result = self.llm.generate([prompt], stop=self.stop_pattern)\n",
        "\n",
        "        # List of the things generated. This is List[List[]] because each input could have multiple generations.\n",
        "        generations = result.generations\n",
        "\n",
        "        # Grab the first text generation, as this will likely be the best result\n",
        "        output = generations[0][0].text\n",
        "\n",
        "        # Parse the result\n",
        "        tool, tool_input = self._get_tool_and_input(output)\n",
        "        return output, tool, tool_input\n",
        "\n",
        "    def _get_tool_and_input(self, generated: str) -> Tuple[str, str]:\n",
        "        if FINAL_ANSWER_TOKEN in generated:\n",
        "            return \"Final Answer\", generated.split(FINAL_ANSWER_TOKEN)[-1].strip()\n",
        "\n",
        "        regex = r\"Action: [\\[]?(.*?)[\\]]?[\\n]*Action Input:[\\s]*(.*)\"\n",
        "        match = re.search(regex, generated, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Output of LLM is not parsable for next tool use: `{generated}`\")\n",
        "        tool = match.group(1).strip()\n",
        "        tool_input = match.group(2)\n",
        "        return tool, tool_input.strip(\" \").strip('\"')"
      ],
      "metadata": {
        "id": "UBqb6bZkagyx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6. Create your Prompt template\n",
        "This prompt will be fed into the Agent's large language model (LLM).  \n",
        "\n",
        "As it \"reasons\" and answers your query, the Agent will update this prompt by appending the previous response (context) to the prompt to maintain context of its overall \"chain of thought\"."
      ],
      "metadata": {
        "id": "_um0nrAlYcw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL_ANSWER_TOKEN = \"Final Answer:\"\n",
        "OBSERVATION_TOKEN = \"Observation:\"\n",
        "THOUGHT_TOKEN = \"Thought:\"\n",
        "PROMPT_TEMPLATE = \"\"\"Answer the question as best as you can using the following tools: \n",
        "\n",
        "{tool_description}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: comment on what you want to do next\n",
        "Action: the action to take, exactly one element of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation repeats N times, use it until you are sure of the answer)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: your final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {question}\n",
        "Thought: {previous_responses}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LXVPO69KZ46c"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7. Run your custom Agent\n",
        "You can update the `question` variable to ask your Agent to answer questions about the PDF that you previously loaded!\n"
      ],
      "metadata": {
        "id": "f-M4SKq7ZFC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The tool(s) that your Agent will use\n",
        "tools = [annual_report_tool]\n",
        "\n",
        "# The question that you will ask your Agent\n",
        "question = \"What was Meta's net income in 2022? What was net income the year before that?\"\n",
        "\n",
        "# The prompt that your Agent will use and update as it is \"reasoning\"\n",
        "prompt = PROMPT_TEMPLATE.format(\n",
        "  tool_description=\"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools]),\n",
        "  tool_names=\", \".join([tool.name for tool in tools]),\n",
        "  question=question,\n",
        "  previous_responses='{previous_responses}',\n",
        ")\n",
        "\n",
        "# The LLM that your Agent will use\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Initialize your Agent\n",
        "agent = Agent(\n",
        "  llm=llm, \n",
        "  tools=tools, \n",
        "  prompt=prompt, \n",
        "  stop_pattern=[f'\\n{OBSERVATION_TOKEN}', f'\\n\\t{OBSERVATION_TOKEN}'],\n",
        ")\n",
        "\n",
        "# Run the Agent!\n",
        "result = agent.run(question)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sGj1TjyEapA9",
        "outputId": "d7a31a97-981a-42b5-d4b0-ff9392c44175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I need to find Meta's net income for 2022 and the previous year. I should use the Annual Report tool to extract this information.\n",
            "Action: Annual Report\n",
            "Action Input: Look for the income statement section of Meta's Annual Report for 2022 and the previous year.\n",
            "Observation: The income statement section can be found in the \"CONSOLIDATED STATEMENTS OF INCOME\" table in Meta's Annual Report for 2022 and the previous year.\n",
            "Thought:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I need to extract the net income data points from the \"CONSOLIDATED STATEMENTS OF INCOME\" table for both years.\n",
            "Action: Annual Report\n",
            "Action Input: Look for the net income line item in the \"CONSOLIDATED STATEMENTS OF INCOME\" table for both years.\n",
            "Observation: Net income for 2022 is $23,200 million and net income for 2021 is $39,370 million.\n",
            "Thought:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rtBXsF7KdbJ2FLARTaQPx208 on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta's net income in 2022 was $23,200 million and net income the year before that was $39,370 million.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can verify whether your Agent's answer about Meta's net income is correct [here](https://www.deepvalue.ai/explore/stocks/META) ðŸ˜ƒ"
      ],
      "metadata": {
        "id": "pWWYSKcNd7Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zUQx5NG5eMUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
