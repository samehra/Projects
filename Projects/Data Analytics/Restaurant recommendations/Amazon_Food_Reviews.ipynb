{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## RECOMMENDATION / MATRIX COMPLETION ALGORITHM BASED ON AMAZON FOOD REVIEWS \n",
    "\n",
    "The problem tackled here is how to help users select products which they may like and to make recommendation to stimulate sales and increase profits. The Amazon Fine Food Reviews dataset which consists of 568,454 food reviews is used for the building the recommendations. Amazon users left up to October 2012 are part of the dataset. Recommendation system is based on users rating prediction. The rating varies between 1 and 5 with 1 being the worst rating and 5 being the best. It is assumed that users tend to like the products that have a score of greater than 4 and the highest 5 scores product are considered as recommendation candidates. Collaborative filtering algorithm is implemented to predict the scores of each product for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# from main import method0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and cleaning\n",
    "\n",
    "Here, Take the data in which the user and item appear more than 10 times in order to reduce the data size.\n",
    "\n",
    "The data() function returns the total number of users and products, the user-item table and also the train & test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def data_clean(df, feature, m):\n",
    "    count = df[feature].value_counts()\n",
    "    df = df[df[feature].isin(count[count > m].index)]\n",
    "    return df\n",
    "\n",
    "def data_clean_sum(df,features,m):\n",
    "    fil = df.ProductId.value_counts()\n",
    "    fil2 = df.UserId.value_counts()\n",
    "    df['#Products'] = df.ProductId.apply(lambda x: fil[x])\n",
    "    df['#Users'] = df.UserId.apply(lambda x: fil2[x])\n",
    "    while ((df.ProductId.value_counts(ascending=True)[0]) < m \n",
    "           or  (df.UserId.value_counts(ascending=True)[0] < m)):\n",
    "        df = data_clean(df,features[0],m)\n",
    "        df = data_clean(df,features[1],m)\n",
    "        print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and formatting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    print('loading data...')\n",
    "    df = pd.read_csv('./input/Reviews.csv')\n",
    "    \n",
    "     # Shape of data frame after loading\n",
    "    print(df.shape)\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df.Time, unit='s')\n",
    "    raw_data = data_clean_sum(df, ['ProductId', 'UserId'], 10)\n",
    "    \n",
    "    # Shape of data frame after loading\n",
    "    print(raw_data.shape)                                                       \n",
    "\n",
    "    # find X,and y\n",
    "    # It is like indexing\n",
    "    raw_data['uid'] = pd.factorize(raw_data['UserId'])[0]                      \n",
    "    raw_data['pid'] = pd.factorize(raw_data['ProductId'])[0]\n",
    "    sc = MinMaxScaler()\n",
    "\n",
    "    #reshape returns a array with 1 column which is transformed to values b/w [0,1]\n",
    "    raw_data['time']=sc.fit_transform(raw_data['Time'].values.reshape(-1,1))    \n",
    "    raw_data['nuser']=sc.fit_transform(raw_data['#Users'].values.reshape(-1,1))\n",
    "    raw_data['nproduct']=sc.fit_transform(raw_data['#Products'].values.reshape(-1,1))\n",
    "    # Seperate the features into three groups\n",
    "    X1 = raw_data.loc[:,['uid','pid']]\n",
    "    X2 = raw_data.loc[:,['uid','pid','time']]\n",
    "    X3 = raw_data.loc[:,['uid','pid','time','nuser','nproduct']]\n",
    "    y = raw_data.Score\n",
    "\n",
    "    # train_test split\n",
    "    X1_train,X1_test,y_train,y_test = \\\n",
    "     train_test_split(X1,y,test_size=0.3,random_state=2017)\n",
    "    X2_train,X2_test,y_train,y_test = \\\n",
    "    train_test_split(X2,y,test_size=0.3,random_state=2017)\n",
    "    X3_train,X3_test,y_train,y_test = \\\n",
    "     train_test_split(X3,y,test_size=0.3,random_state=2017)\n",
    "    \n",
    "    train = np.array(X1_train.join(y_train))\n",
    "    test = np.array(X1_test.join(y_test))\n",
    "    # got the productId to pid index\n",
    "    pid2PID = raw_data.ProductId.unique()\n",
    "\n",
    "    data_mixed = X1.join(y)\n",
    "    data_mixed['uid'] = data_mixed['uid'].astype(int)\n",
    "    data_mixed['pid'] = data_mixed['pid'].astype(int)\n",
    "    data_mixed['Score'] = data_mixed['Score'].astype(int)\n",
    "    total_p = data_mixed['pid'].unique().shape[0]\n",
    "    total_u = data_mixed['uid'].unique().shape[0]\n",
    "    \n",
    "    # make the user-item table\n",
    "    table = np.zeros([total_u,total_p])\n",
    "    z = np.array(data_mixed)\n",
    "    for line in z:\n",
    "        u,p,s = line\n",
    "        if table[u][p] < s:\n",
    "            table[u][p] = s #if some one score a single thing several times\n",
    "    print('the table\\'s shape is:' )\n",
    "    print(table.shape)\n",
    "    return z, total_u,total_p,pid2PID,train,test,table,raw_data, data_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating the cost and gradient functions for Collaborative Filtering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're given the the product features we can use that to find out the users' preference parameters.\n",
    "\n",
    " \\ \n",
    "**_Given $x^{(1)},....,x^{(n_m)}$, estimate $\\theta^{(1)},....,\\theta^{(n_u)}$:_**<br>\n",
    "\n",
    " \\ \n",
    "<center>$\\large\\displaystyle\\min_{\\theta^{(1)},....,\\theta^{(n_u)}} 1/2 \\displaystyle\\sum_{j=1}^{n_u} \\displaystyle\\sum_{i:r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\lambda/2\\displaystyle\\sum_{j=1}^{n_u} \\displaystyle\\sum_{k=1}^n(\\theta_k^{(j)})^2$<br>\n",
    "    \n",
    " \\ \n",
    "If we're given the users' preferences parameters we can use them to work out the product features.\n",
    "\n",
    " \\   \n",
    "**_Given $\\theta^{(1)},....,\\theta^{(n_u)}$, estimate $x^{(1)},....,x^{(n_m)}$:_**<br>\n",
    "\n",
    " \\ \n",
    "<center>$\\large\\displaystyle\\min_{x^{(1)},....,x^{(n_m)}} 1/2 \\displaystyle\\sum_{i=1}^{n_m} \\displaystyle\\sum_{j:r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\lambda/2\\displaystyle\\sum_{i=1}^{n_m} \\displaystyle\\sum_{k=1}^n(x_k^{(i)})^2$<br>\n",
    "    \n",
    " \\ \n",
    "The loss function for the Collaborative Filtering can be defined as:\n",
    "\n",
    " \\   \n",
    "**_Minimizing $x^{(1)},....,x^{(n_m)}$ and $\\theta^{(1)},....,\\theta^{(n_u)}$ simultaneously:_**<br>\n",
    "\n",
    " \\ \n",
    " <center>$\\large J(x^{(1)},....,x^{(n_m)}, \\theta^{(1)},....,\\theta^{(n_u)}) = 1/2 \\displaystyle\\sum_{(i,j):r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\lambda/2\\displaystyle\\sum_{i=1}^{n_m} \\displaystyle\\sum_{k=1}^n(x_k^{(i)})^2 + \\lambda/2\\displaystyle\\sum_{j=1}^{n_u} \\displaystyle\\sum_{k=1}^n(\\theta_k^{(j)})^2$<br>\n",
    "     \n",
    " \\ \n",
    "where we want to estimate the users' preferences parameters and product features such that the loss function is minimized.\n",
    "\n",
    " \\ \n",
    "<center>$\\large\\displaystyle\\min_{{x^{(1)},....,x^{(n_m)}}{\\theta^{(1)},....,\\theta^{(n_u)}}} J(x^{(1)},....,x^{(n_m)}, \\theta^{(1)},....,\\theta^{(n_u)})$\n",
    "    \n",
    " \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0,
     12,
     21
    ]
   },
   "outputs": [],
   "source": [
    "def normalize (Y, A):\n",
    "    m, n = Y.shape\n",
    "    Y_mean = np.zeros((m, 1))\n",
    "    Y_norm = np.zeros(Y.shape)\n",
    "    for i in range(0,Y.shape[0]):\n",
    "        idx = np.nonzero(A[i])\n",
    "        Y_mean[i] = np.mean(Y[i, idx], axis = 1)\n",
    "        Y_norm[i,idx] = Y[i,idx] - Y_mean[i]\n",
    "    \n",
    "    Ymean = np.nan_to_num(Y_mean)\n",
    "    return Y_norm, Ymean\n",
    "\n",
    "def CostFunc(params, Y, A, num_users, num_prod, num_features, lamda):\n",
    "    # Unfold the X and Theta matrices from params\n",
    "    X = np.reshape(params[0:num_prod*num_features],(num_prod,num_features))\n",
    "    Theta = np.reshape(params[num_prod*num_features:],(num_users,num_features))\n",
    "\n",
    "    J = (1/2)*sum(sum(((X.dot(Theta.T) - Y) * A)**2)) + (lamda/2) * sum(sum(Theta**2)) + (lamda/2) * sum(sum(X**2))\n",
    "\n",
    "    return J\n",
    "\n",
    "def GradFunc(params, Y, A, num_users, num_prod, num_features, lamda):\n",
    "    \n",
    "    # Unfold the X and Theta matrices from params\n",
    "    X = np.reshape(params[0:num_prod*num_features],(num_prod,num_features))\n",
    "    Theta = np.reshape(params[num_prod*num_features:],(num_users,num_features))\n",
    "\n",
    "\n",
    "    # You need to return the following values correctly\n",
    "    X_grad = np.zeros(X.shape)\n",
    "    Theta_grad = np.zeros(Theta.shape)\n",
    "    \n",
    "    X_grad = ((X.dot(Theta.T) - Y) * A).dot(Theta) + lamda * X\n",
    "\n",
    "    Theta_grad = ((X.dot(Theta.T) - Y) * A).T.dot(X) + lamda * Theta\n",
    "\n",
    "    grad = np.concatenate((X_grad.flatten(),Theta_grad.flatten()), axis=0)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering algorithm can be summarized as:\n",
    "\n",
    "1) Initialize $x^{(1)},....,x^{(n_m)}, \\theta^{(1)},....\\theta^{(n_u)}$ to small random values.\n",
    "\n",
    "2) Minimize $J(x^{(1)},....,x^{(n_m)}, \\theta^{(1)},....\\theta^{(n_u)})$ using gradient descent (or an advanced optimization algorithm). E.g. for every: $j = 1,...,n_u, i = 1,...,n_m$:\n",
    "\n",
    "<center>$\\large{x_k}^{(i)} := {x_k}^{(i)} - \\alpha\\Bigg(\\displaystyle\\sum_{j:r(i,j)=1}((\\theta^{(j)})^T x^{(i)} - y^{(i,j)}){\\theta_k}^{(j)} + \\lambda{x_k}^{(i)}\\Bigg)$</center>\n",
    "\n",
    "<center>$\\large{\\theta_k}^{(j)} := {\\theta_k}^{(j)} - \\alpha\\Bigg(\\displaystyle\\sum_{i:r(i,j)=1}((\\theta^{(j)})^T x^{(i)} - y^{(i,j)}){x_k}^{(i)} + \\lambda{\\theta_k}^{(j)}\\Bigg)$</center>\n",
    "\n",
    "3) For a user with parameters $\\theta$ and a product with (learned) features $x$, predict a star rating of $\\theta^Tx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining system parameters and defining initial feature and parameter values for the Collaborative Filtering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "(568454, 7)\n",
      "(95552, 10)\n",
      "(67756, 10)\n",
      "(64771, 10)\n",
      "(64340, 10)\n",
      "(64340, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the table's shape is:\n",
      "(3666, 1102)\n"
     ]
    }
   ],
   "source": [
    "z, total_u,total_p,pid2PID,train,test,table,raw_data, data_mixed = data()\n",
    "A = ((table!=0) * 1).T\n",
    "Y = table.T\n",
    "num_features = 10; num_prod = A.shape[0]; num_users = A.shape[1];\n",
    "X = np.random.random((num_prod,num_features))\n",
    "Theta = np.random.random((num_users,num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimization algorithm and finding the optimal feature and parameter values for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 29582.779346\n",
      "         Iterations: 200\n",
      "         Function evaluations: 298\n",
      "         Gradient evaluations: 298\n",
      "Recommender system learning completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean normalization\n",
    "Y_norm, Y_mean = normalize(Y, A)\n",
    "\n",
    "# Merging the X and Theta values into a 1-D array for input to optimization algo\n",
    "Inp = np.concatenate((X.flatten(),Theta.flatten()), axis=0)\n",
    "\n",
    "# Defining system parameter values\n",
    "lamda = 20\n",
    "args = (Y_norm, A, num_users, num_prod, num_features, lamda)  # arguments values\n",
    "\n",
    "# Conjugate gradient optimization algorithm\n",
    "res = optimize.fmin_cg(CostFunc, Inp, fprime=GradFunc, args=args, maxiter = 200)\n",
    "\n",
    "# Optimal Cost and Gradient values after optimization\n",
    "J = CostFunc(res, *args)\n",
    "grad = GradFunc(res, *args)\n",
    "\n",
    "# Unfold the returned theta back into P and U\n",
    "X = np.reshape(res[0:num_prod*num_features],(num_prod,num_features))\n",
    "Theta = np.reshape(res[num_prod*num_features:],(num_users,num_features))\n",
    "\n",
    "print('Recommender system learning completed.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommended products (pid) for userid 1 are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>837</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>607</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>905</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>781</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  ratings\n",
       "0  468        5\n",
       "1  768        5\n",
       "2  154        5\n",
       "3  374        4\n",
       "4  837        4\n",
       "5  323        4\n",
       "6  607        4\n",
       "7  905        4\n",
       "8  858        4\n",
       "9  781        4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ================== Generating recommendation ===============\n",
    "#  After training the model, we can now make recommendations \n",
    "# by computing the prediction matrix.\n",
    "\n",
    "p = X.dot(Theta.T)\n",
    "prediction = np.around(p + Y_mean.reshape(-1,1),2)\n",
    "\n",
    "k = 1\n",
    "\n",
    "# adding an index column to ratings\n",
    "t1 = np.vstack((np.arange(0,Y.shape[0]),prediction[:,k])).T \n",
    "# Sorting in descending order by ratings\n",
    "Rating_userK = t1[t1[:,1].argsort()[::-1]]                       \n",
    "\n",
    "print('\\nTop 10 recommended products (pid) for userid %d are:\\n' % k)\n",
    "pd.DataFrame(Rating_userK[0:10].astype(int), columns = ['pid', 'ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.74, 4.73, 4.73, ..., 3.98, 3.98, 3.98],\n",
       "       [4.14, 4.14, 4.14, ..., 4.09, 4.09, 4.09],\n",
       "       [4.5 , 4.5 , 4.5 , ..., 4.5 , 4.5 , 4.5 ],\n",
       "       ...,\n",
       "       [4.18, 4.19, 4.19, ..., 4.14, 4.14, 4.14],\n",
       "       [4.47, 4.47, 4.47, ..., 4.47, 4.47, 4.47],\n",
       "       [3.12, 3.12, 3.12, ..., 3.13, 3.13, 3.13]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09400737508234638\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(Y, prediction * A))\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
